{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c658a6a-1472-4ded-b248-7ecdebbd19e8",
   "metadata": {},
   "source": [
    "## SetB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f61e06-a2a5-4bf8-a4fa-20150bb0ed52",
   "metadata": {},
   "source": [
    "## 1. Write a python program to rescale the data between 0 and 1. (use inbuilt dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39ba5b7-ba21-4767-96ef-f2de9afa1349",
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale technique :\n",
    "Feature Scaling:\n",
    "used for machine learning models working on image processing with pixels\n",
    "Feature Scaling or Standardization: It is a step of Data Pre Processing that is\n",
    "applied to independent variables or features of data. It basically helps to normalize the\n",
    "data within a particular range. Sometimes, it also helps in speeding up the calculations in\n",
    "an algorithm.\n",
    "Min-Max Normalization: This technique re-scales a feature or observation value with\n",
    "distribution value between 0 and 1.\n",
    "    x_normalization = x     -    min(x)\n",
    "                    -------------------\n",
    "                      max(x) -   min(x)\n",
    "\n",
    "Standardization: It is a very effective technique which re-scales a feature value so that\n",
    "it has distribution with 0 mean value and variance equals to 1.\n",
    "\n",
    "    x_standardization =  x    -   mean(x)\n",
    "                        ------------------\n",
    "                        standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a0e97e-a9d1-430c-af7a-b43dc83ccc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "\n",
    "**Why Use Feature Scaling?**\n",
    "\n",
    "1. **Ensures Uniform Scale**:\n",
    "   - Different features in a dataset can have vastly different ranges (e.g., age vs. income).\n",
    "   - Without scaling, features with larger ranges can dominate the learning process, leading to biased models.\n",
    "\n",
    "2. **Improves Convergence Speed**:\n",
    "   - Algorithms like gradient descent converge faster with feature scaling.\n",
    "   - Scaling ensures that gradient steps are consistent across all features.\n",
    "\n",
    "3. **Enhances Model Performance**:\n",
    "   - Distance-based algorithms (e.g., KNN, SVM) are sensitive to the scale of the data.\n",
    "   - Scaling ensures all features contribute equally to distance calculations, improving performance.\n",
    "\n",
    "4. **Prevents Numerical Instability**:\n",
    "   - Features with large values can cause numerical problems during computations.\n",
    "   - Scaling helps maintain numerical stability, preventing overflow and ensuring reliable model training.\n",
    "\n",
    "5. **Facilitates Feature Comparison**:\n",
    "   - Scaling makes it easier to interpret and compare the importance of different features in the model.\n",
    "\n",
    "6. **Necessary for Principal Component Analysis (PCA)**:\n",
    "   - PCA is sensitive to the variances of the features.\n",
    "   - Scaling ensures all features contribute equally to the principal components.\n",
    "\n",
    "**Common Methods of Feature Scaling**:\n",
    "\n",
    "1. **Normalization (Min-Max Scaling)**:\n",
    "   - Formula: `X' = (X - X_min) / (X_max - X_min)`\n",
    "   - Scales features to a fixed range, usually [0, 1].\n",
    "\n",
    "2. **Standardization (Z-score Scaling)**:\n",
    "   - Formula: `X' = (X - μ) / σ`\n",
    "   - Transforms features to have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "3. **Robust Scaling**:\n",
    "   - Formula: `X' = (X - median) / IQR` (Interquartile Range)\n",
    "   - Reduces the influence of outliers.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30f6d469-51c4-4877-8be3-86a30e78cfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in d:\\software_installed\\anaconda\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in d:\\software_installed\\anaconda\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in d:\\software_installed\\anaconda\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\software_installed\\anaconda\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\software_installed\\anaconda\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\software_installed\\anaconda\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\software_installed\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in d:\\software_installed\\anaconda\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\software_installed\\anaconda\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in d:\\software_installed\\anaconda\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\software_installed\\anaconda\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\software_installed\\anaconda\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: seaborn in d:\\software_installed\\anaconda\\lib\\site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in d:\\software_installed\\anaconda\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.25 in d:\\software_installed\\anaconda\\lib\\site-packages (from seaborn) (2.1.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in d:\\software_installed\\anaconda\\lib\\site-packages (from seaborn) (3.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\software_installed\\anaconda\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\software_installed\\anaconda\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\software_installed\\anaconda\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\software_installed\\anaconda\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\software_installed\\anaconda\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\software_installed\\anaconda\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\software_installed\\anaconda\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\software_installed\\anaconda\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\software_installed\\anaconda\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\software_installed\\anaconda\\lib\\site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\software_installed\\anaconda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement matplotilb (from versions: none)\n",
      "ERROR: No matching distribution found for matplotilb\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install scikit-learn\n",
    "!pip install seaborn\n",
    "!pip install matplotilb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be128e-62a6-4edf-ba07-8ac9e908f6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inbuilt data sets\n",
    "load_boston([return_X_y])\tLoad and return the boston house-prices dataset (regression).\n",
    "load_iris([return_X_y])\tLoad and return the iris dataset (classification).\n",
    "load_diabetes([return_X_y])\tLoad and return the diabetes dataset (regression).\n",
    "load_digits([n_class, return_X_y])\tLoad and return the digits dataset (classification).\n",
    "load_linnerud([return_X_y])\tLoad and return the linnerud dataset (multivariate regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6d7b3c5-183c-4588-96f4-d967c24f2c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import Dataset:\n",
      "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                  5.1               3.5                1.4               0.2\n",
      "1                  4.9               3.0                1.4               0.2\n",
      "2                  4.7               3.2                1.3               0.2\n",
      "3                  4.6               3.1                1.5               0.2\n",
      "4                  5.0               3.6                1.4               0.2\n",
      "5                  5.4               3.9                1.7               0.4\n",
      "6                  4.6               3.4                1.4               0.3\n",
      "7                  5.0               3.4                1.5               0.2\n",
      "8                  4.4               2.9                1.4               0.2\n",
      "9                  4.9               3.1                1.5               0.1\n",
      "10                 5.4               3.7                1.5               0.2\n",
      "11                 4.8               3.4                1.6               0.2\n",
      "12                 4.8               3.0                1.4               0.1\n",
      "13                 4.3               3.0                1.1               0.1\n",
      "14                 5.8               4.0                1.2               0.2\n",
      "15                 5.7               4.4                1.5               0.4\n",
      "16                 5.4               3.9                1.3               0.4\n",
      "17                 5.1               3.5                1.4               0.3\n",
      "18                 5.7               3.8                1.7               0.3\n",
      "19                 5.1               3.8                1.5               0.3\n",
      "20                 5.4               3.4                1.7               0.2\n",
      "21                 5.1               3.7                1.5               0.4\n",
      "22                 4.6               3.6                1.0               0.2\n",
      "23                 5.1               3.3                1.7               0.5\n",
      "24                 4.8               3.4                1.9               0.2\n",
      "25                 5.0               3.0                1.6               0.2\n",
      "26                 5.0               3.4                1.6               0.4\n",
      "27                 5.2               3.5                1.5               0.2\n",
      "28                 5.2               3.4                1.4               0.2\n",
      "29                 4.7               3.2                1.6               0.2\n",
      "30                 4.8               3.1                1.6               0.2\n",
      "31                 5.4               3.4                1.5               0.4\n",
      "32                 5.2               4.1                1.5               0.1\n",
      "33                 5.5               4.2                1.4               0.2\n",
      "34                 4.9               3.1                1.5               0.2\n",
      "35                 5.0               3.2                1.2               0.2\n",
      "36                 5.5               3.5                1.3               0.2\n",
      "37                 4.9               3.6                1.4               0.1\n",
      "38                 4.4               3.0                1.3               0.2\n",
      "39                 5.1               3.4                1.5               0.2\n",
      "40                 5.0               3.5                1.3               0.3\n",
      "41                 4.5               2.3                1.3               0.3\n",
      "42                 4.4               3.2                1.3               0.2\n",
      "43                 5.0               3.5                1.6               0.6\n",
      "44                 5.1               3.8                1.9               0.4\n",
      "45                 4.8               3.0                1.4               0.3\n",
      "46                 5.1               3.8                1.6               0.2\n",
      "47                 4.6               3.2                1.4               0.2\n",
      "48                 5.3               3.7                1.5               0.2\n",
      "49                 5.0               3.3                1.4               0.2\n",
      "50                 7.0               3.2                4.7               1.4\n",
      "51                 6.4               3.2                4.5               1.5\n",
      "52                 6.9               3.1                4.9               1.5\n",
      "53                 5.5               2.3                4.0               1.3\n",
      "54                 6.5               2.8                4.6               1.5\n",
      "55                 5.7               2.8                4.5               1.3\n",
      "56                 6.3               3.3                4.7               1.6\n",
      "57                 4.9               2.4                3.3               1.0\n",
      "58                 6.6               2.9                4.6               1.3\n",
      "59                 5.2               2.7                3.9               1.4\n",
      "60                 5.0               2.0                3.5               1.0\n",
      "61                 5.9               3.0                4.2               1.5\n",
      "62                 6.0               2.2                4.0               1.0\n",
      "63                 6.1               2.9                4.7               1.4\n",
      "64                 5.6               2.9                3.6               1.3\n",
      "65                 6.7               3.1                4.4               1.4\n",
      "66                 5.6               3.0                4.5               1.5\n",
      "67                 5.8               2.7                4.1               1.0\n",
      "68                 6.2               2.2                4.5               1.5\n",
      "69                 5.6               2.5                3.9               1.1\n",
      "70                 5.9               3.2                4.8               1.8\n",
      "71                 6.1               2.8                4.0               1.3\n",
      "72                 6.3               2.5                4.9               1.5\n",
      "73                 6.1               2.8                4.7               1.2\n",
      "74                 6.4               2.9                4.3               1.3\n",
      "75                 6.6               3.0                4.4               1.4\n",
      "76                 6.8               2.8                4.8               1.4\n",
      "77                 6.7               3.0                5.0               1.7\n",
      "78                 6.0               2.9                4.5               1.5\n",
      "79                 5.7               2.6                3.5               1.0\n",
      "80                 5.5               2.4                3.8               1.1\n",
      "81                 5.5               2.4                3.7               1.0\n",
      "82                 5.8               2.7                3.9               1.2\n",
      "83                 6.0               2.7                5.1               1.6\n",
      "84                 5.4               3.0                4.5               1.5\n",
      "85                 6.0               3.4                4.5               1.6\n",
      "86                 6.7               3.1                4.7               1.5\n",
      "87                 6.3               2.3                4.4               1.3\n",
      "88                 5.6               3.0                4.1               1.3\n",
      "89                 5.5               2.5                4.0               1.3\n",
      "90                 5.5               2.6                4.4               1.2\n",
      "91                 6.1               3.0                4.6               1.4\n",
      "92                 5.8               2.6                4.0               1.2\n",
      "93                 5.0               2.3                3.3               1.0\n",
      "94                 5.6               2.7                4.2               1.3\n",
      "95                 5.7               3.0                4.2               1.2\n",
      "96                 5.7               2.9                4.2               1.3\n",
      "97                 6.2               2.9                4.3               1.3\n",
      "98                 5.1               2.5                3.0               1.1\n",
      "99                 5.7               2.8                4.1               1.3\n",
      "100                6.3               3.3                6.0               2.5\n",
      "101                5.8               2.7                5.1               1.9\n",
      "102                7.1               3.0                5.9               2.1\n",
      "103                6.3               2.9                5.6               1.8\n",
      "104                6.5               3.0                5.8               2.2\n",
      "105                7.6               3.0                6.6               2.1\n",
      "106                4.9               2.5                4.5               1.7\n",
      "107                7.3               2.9                6.3               1.8\n",
      "108                6.7               2.5                5.8               1.8\n",
      "109                7.2               3.6                6.1               2.5\n",
      "110                6.5               3.2                5.1               2.0\n",
      "111                6.4               2.7                5.3               1.9\n",
      "112                6.8               3.0                5.5               2.1\n",
      "113                5.7               2.5                5.0               2.0\n",
      "114                5.8               2.8                5.1               2.4\n",
      "115                6.4               3.2                5.3               2.3\n",
      "116                6.5               3.0                5.5               1.8\n",
      "117                7.7               3.8                6.7               2.2\n",
      "118                7.7               2.6                6.9               2.3\n",
      "119                6.0               2.2                5.0               1.5\n",
      "120                6.9               3.2                5.7               2.3\n",
      "121                5.6               2.8                4.9               2.0\n",
      "122                7.7               2.8                6.7               2.0\n",
      "123                6.3               2.7                4.9               1.8\n",
      "124                6.7               3.3                5.7               2.1\n",
      "125                7.2               3.2                6.0               1.8\n",
      "126                6.2               2.8                4.8               1.8\n",
      "127                6.1               3.0                4.9               1.8\n",
      "128                6.4               2.8                5.6               2.1\n",
      "129                7.2               3.0                5.8               1.6\n",
      "130                7.4               2.8                6.1               1.9\n",
      "131                7.9               3.8                6.4               2.0\n",
      "132                6.4               2.8                5.6               2.2\n",
      "133                6.3               2.8                5.1               1.5\n",
      "134                6.1               2.6                5.6               1.4\n",
      "135                7.7               3.0                6.1               2.3\n",
      "136                6.3               3.4                5.6               2.4\n",
      "137                6.4               3.1                5.5               1.8\n",
      "138                6.0               3.0                4.8               1.8\n",
      "139                6.9               3.1                5.4               2.1\n",
      "140                6.7               3.1                5.6               2.4\n",
      "141                6.9               3.1                5.1               2.3\n",
      "142                5.8               2.7                5.1               1.9\n",
      "143                6.8               3.2                5.9               2.3\n",
      "144                6.7               3.3                5.7               2.5\n",
      "145                6.7               3.0                5.2               2.3\n",
      "146                6.3               2.5                5.0               1.9\n",
      "147                6.5               3.0                5.2               2.0\n",
      "148                6.2               3.4                5.4               2.3\n",
      "149                5.9               3.0                5.1               1.8\n",
      "plot data using sns:\n",
      "rescale data and plot:\n",
      "[0.22222222 0.16666667 0.11111111 0.08333333 0.19444444 0.30555556\n",
      " 0.08333333 0.19444444 0.02777778 0.16666667 0.30555556 0.13888889\n",
      " 0.13888889 0.         0.41666667 0.38888889 0.30555556 0.22222222\n",
      " 0.38888889 0.22222222 0.30555556 0.22222222 0.08333333 0.22222222\n",
      " 0.13888889 0.19444444 0.19444444 0.25       0.25       0.11111111\n",
      " 0.13888889 0.30555556 0.25       0.33333333 0.16666667 0.19444444\n",
      " 0.33333333 0.16666667 0.02777778 0.22222222 0.19444444 0.05555556\n",
      " 0.02777778 0.19444444 0.22222222 0.13888889 0.22222222 0.08333333\n",
      " 0.27777778 0.19444444 0.75       0.58333333 0.72222222 0.33333333\n",
      " 0.61111111 0.38888889 0.55555556 0.16666667 0.63888889 0.25\n",
      " 0.19444444 0.44444444 0.47222222 0.5        0.36111111 0.66666667\n",
      " 0.36111111 0.41666667 0.52777778 0.36111111 0.44444444 0.5\n",
      " 0.55555556 0.5        0.58333333 0.63888889 0.69444444 0.66666667\n",
      " 0.47222222 0.38888889 0.33333333 0.33333333 0.41666667 0.47222222\n",
      " 0.30555556 0.47222222 0.66666667 0.55555556 0.36111111 0.33333333\n",
      " 0.33333333 0.5        0.41666667 0.19444444 0.36111111 0.38888889\n",
      " 0.38888889 0.52777778 0.22222222 0.38888889 0.55555556 0.41666667\n",
      " 0.77777778 0.55555556 0.61111111 0.91666667 0.16666667 0.83333333\n",
      " 0.66666667 0.80555556 0.61111111 0.58333333 0.69444444 0.38888889\n",
      " 0.41666667 0.58333333 0.61111111 0.94444444 0.94444444 0.47222222\n",
      " 0.72222222 0.36111111 0.94444444 0.55555556 0.66666667 0.80555556\n",
      " 0.52777778 0.5        0.58333333 0.80555556 0.86111111 1.\n",
      " 0.58333333 0.55555556 0.5        0.94444444 0.55555556 0.58333333\n",
      " 0.47222222 0.72222222 0.66666667 0.72222222 0.41666667 0.69444444\n",
      " 0.66666667 0.66666667 0.55555556 0.61111111 0.52777778 0.44444444]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software_Installed\\anaconda\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "D:\\Software_Installed\\anaconda\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='sepal length (cm)', ylabel='Count'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import preprocessing as per\n",
    "import seaborn as sns\n",
    "\n",
    "iris=load_iris()\n",
    "#with pd.option_context('mode.use_inf_as_na', True):\n",
    "#import dataset\n",
    "print(\"Import Dataset:\")\n",
    "df=pd.DataFrame(iris['data'],columns=iris['feature_names'])\n",
    "print(df.to_string())\n",
    "# plot data using sns\n",
    "print(\"plot data using sns:\")\n",
    "xcol=df['sepal length (cm)']\n",
    "sns.set(style=\"dark\")\n",
    "sns.histplot(data=xcol)\n",
    "#rescale\n",
    "print(\"rescale data and plot:\")\n",
    "xcol2=per.minmax_scale(df['sepal length (cm)'],feature_range=(0,1))\n",
    "print(xcol2)\n",
    "sns.set(style=\"dark\")\n",
    "sns.histplot(data=xcol2,color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb77af9d-6b79-4679-94f7-307f9d6e418f",
   "metadata": {},
   "source": [
    "## 2. Write a python program to splitting the dataset into training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a189c9ab-d150-446f-b0c3-277899f9ecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Splitting a dataset into training and testing sets is a fundamental step in machine learning and statistical modeling. It involves dividing the dataset into two parts: one part is used to train the model, and the other part is used to evaluate the model's performance. Here's what each part represents:\n",
    "\n",
    "Training Set:\n",
    "\n",
    "Purpose: Used to train the machine learning model. This means the model learns the patterns, relationships, and structure of the data from this set.\n",
    "Process: The model adjusts its internal parameters based on this data to minimize errors and improve accuracy.\n",
    "Size: Typically larger than the testing set, often comprising 70-80% of the total dataset.\n",
    "Testing Set:\n",
    "\n",
    "Purpose: Used to evaluate the performance of the trained model. It acts as new, unseen data for the model to make predictions.\n",
    "Process: After the model is trained, it is tested on this data to see how well it generalizes to new data. This helps in assessing the model's accuracy, precision, recall, etc.\n",
    "Size: Typically smaller than the training set, often comprising 20-30% of the total dataset.\n",
    "Why Split the Dataset?\n",
    "Avoid Overfitting:\n",
    "\n",
    "Overfitting: A model that performs extremely well on the training data but fails to generalize to new, unseen data.\n",
    "Purpose: By evaluating the model on a separate testing set, we can detect overfitting. If the model performs well on both the training and testing sets, it indicates good generalization.\n",
    "Model Validation:\n",
    "\n",
    "Purpose: The testing set provides an unbiased evaluation of the model's performance. It simulates how the model would perform in the real world.\n",
    "Hyperparameter Tuning:\n",
    "\n",
    "Purpose: Helps in selecting the best model parameters (e.g., learning rate, number of layers in a neural network) by providing a way to test different configurations.\n",
    "Example Scenario\n",
    "Imagine you have a dataset of house prices with features like the number of bedrooms, size of the house, location, etc., and you want to build a model to predict house prices:\n",
    "\n",
    "Training Set:\n",
    "\n",
    "Data: 80% of your dataset.\n",
    "Usage: The model learns the relationship between the features (e.g., number of bedrooms) and the target (e.g., house price).\n",
    "Testing Set:\n",
    "\n",
    "Data: 20% of your dataset.\n",
    "Usage: After training, the model is evaluated on this set to see how well it predicts house prices on new, unseen data.\n",
    "By splitting the dataset, you ensure that the model is trained and evaluated properly, leading to more reliable and generalizable predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68116c78-c625-4a66-92d2-ef757c2d20d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Outlook Temperature Humidity    Wind Play Tennis\n",
      "0      Sunny         Hot     High    Weak          No\n",
      "1      Sunny         Hot     High  Strong          No\n",
      "2   Overcast         Hot     High    Weak         Yes\n",
      "3       Rain        Mild     High    Weak         Yes\n",
      "4       Rain        Cool   Normal    Weak         Yes\n",
      "5       Rain        Cool   Normal  Strong          No\n",
      "6   Overcast        Cool   Normal  Strong         Yes\n",
      "7      Sunny        Mild     High    Weak          No\n",
      "8      Sunny        Cool   Normal    Weak         Yes\n",
      "9       Rain        Mild   Normal    Weak         Yes\n",
      "10     Sunny        Mild   Normal  Strong         Yes\n",
      "11  Overcast        Mild     High  Strong         Yes\n",
      "12  Overcast         Hot   Normal    Weak         Yes\n",
      "13      Rain        Mild     High  Strong          No\n",
      "\n",
      "Features x=     Outlook Temperature Humidity    Wind\n",
      "0      Sunny         Hot     High    Weak\n",
      "1      Sunny         Hot     High  Strong\n",
      "2   Overcast         Hot     High    Weak\n",
      "3       Rain        Mild     High    Weak\n",
      "4       Rain        Cool   Normal    Weak\n",
      "5       Rain        Cool   Normal  Strong\n",
      "6   Overcast        Cool   Normal  Strong\n",
      "7      Sunny        Mild     High    Weak\n",
      "8      Sunny        Cool   Normal    Weak\n",
      "9       Rain        Mild   Normal    Weak\n",
      "10     Sunny        Mild   Normal  Strong\n",
      "11  Overcast        Mild     High  Strong\n",
      "12  Overcast         Hot   Normal    Weak\n",
      "13      Rain        Mild     High  Strong\n",
      "\n",
      "target y=0      No\n",
      "1      No\n",
      "2     Yes\n",
      "3     Yes\n",
      "4     Yes\n",
      "5      No\n",
      "6     Yes\n",
      "7      No\n",
      "8     Yes\n",
      "9     Yes\n",
      "10    Yes\n",
      "11    Yes\n",
      "12    Yes\n",
      "13     No\n",
      "Name: Play Tennis, dtype: object\n",
      "\n",
      "x_train=\n",
      "     Outlook Temperature Humidity    Wind\n",
      "11  Overcast        Mild     High  Strong\n",
      "2   Overcast         Hot     High    Weak\n",
      "13      Rain        Mild     High  Strong\n",
      "9       Rain        Mild   Normal    Weak\n",
      "1      Sunny         Hot     High  Strong\n",
      "7      Sunny        Mild     High    Weak\n",
      "10     Sunny        Mild   Normal  Strong\n",
      "3       Rain        Mild     High    Weak\n",
      "0      Sunny         Hot     High    Weak\n",
      "5       Rain        Cool   Normal  Strong\n",
      "12  Overcast         Hot   Normal    Weak\n",
      "\n",
      "x_train shape\n",
      "=(11, 4)\n",
      "\n",
      "x_test\n",
      "=    Outlook Temperature Humidity    Wind\n",
      "8     Sunny        Cool   Normal    Weak\n",
      "6  Overcast        Cool   Normal  Strong\n",
      "4      Rain        Cool   Normal    Weak\n",
      "\n",
      "x_test shape\n",
      "=(3, 4)\n",
      "\n",
      "y_train=\n",
      "11    Yes\n",
      "2     Yes\n",
      "13     No\n",
      "9     Yes\n",
      "1      No\n",
      "7      No\n",
      "10    Yes\n",
      "3     Yes\n",
      "0      No\n",
      "5      No\n",
      "12    Yes\n",
      "Name: Play Tennis, dtype: object\n",
      "\n",
      "y_train shape\n",
      "=(11,)\n",
      "\n",
      "y_test\n",
      "=8    Yes\n",
      "6    Yes\n",
      "4    Yes\n",
      "Name: Play Tennis, dtype: object\n",
      "\n",
      "y_test shape\n",
      "=(3,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Jul 18 19:13:21 2024\n",
    "\n",
    "@author: bagew\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "filepath=r\"C:\\Users\\bagew\\Downloads\\DataSci\\Datasets\\PlayTennis.csv\"\n",
    "df=pd.read_csv(filepath)\n",
    "print(f\"{df}\\n\")\n",
    "\n",
    "#features independent vairables\n",
    "x=df[['Outlook','Temperature','Humidity','Wind']]\n",
    "\"\"\"\n",
    "By passing this list inside double square brackets, you are instructing Pandas\n",
    "to return a new DataFrame that contains only these specified columns.\n",
    "\"\"\"\n",
    "print(f\"Features x={x}\\n\")\n",
    "\n",
    "#target dependent vairables\n",
    "y=df['Play Tennis']\n",
    "print(f\"target y={y}\\n\")\n",
    "\n",
    "\"\"\"\n",
    "Training Set:\n",
    "Data: 80% of your dataset.\n",
    "Usage: The model learns the relationship between the features (e.g., number of bedrooms) \n",
    "and the target (e.g., house price).\n",
    "\n",
    "Testing Set:\n",
    "Data: 20% of your dataset.\n",
    "Usage: After training, the model is evaluated on this set to see how well it predicts house prices on new, unseen data.\n",
    "\n",
    "The random_state parameter is used to ensure reproducibility \n",
    "when splitting data into training and testing sets or \n",
    "when performing other random operations in machine learning. \n",
    "By setting random_state=42, you ensure that every time you run your code, \n",
    "you get the same split, making it easier to debug and compare results.\n",
    "\"\"\"\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)\n",
    "print(f\"x_train=\\n{x_train}\\n\")\n",
    "print(f\"x_train shape\\n={x_train.shape}\\n\")\n",
    "print(f\"x_test\\n={x_test}\\n\")\n",
    "print(f\"x_test shape\\n={x_test.shape}\\n\")\n",
    "print(f\"y_train=\\n{y_train}\\n\")\n",
    "print(f\"y_train shape\\n={y_train.shape}\\n\")\n",
    "print(f\"y_test\\n={y_test}\\n\")\n",
    "print(f\"y_test shape\\n={y_test.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dc0548-029c-4d1f-99b5-2a580549e9f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
